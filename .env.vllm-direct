# DeepSeek-OCR vLLM Direct 配置示例
# 复制此文件为 .env 并根据需要修改

# ==================== 模型配置 ====================
# 模型路径（本地路径或 HuggingFace/ModelScope 模型名）
MODEL_PATH=deepseek-ai/DeepSeek-OCR

# ==================== vLLM 引擎配置 ====================
# 使用 v1 引擎实现（强制开启，确保与新版兼容）
VLLM_USE_V1=1

# ==================== GPU 配置 ====================
# 张量并行大小（多卡推理时设置）
TENSOR_PARALLEL_SIZE=1

# GPU 内存利用率（0.0-1.0）
GPU_MEMORY_UTILIZATION=0.75

# 最大模型长度（token 数）
MAX_MODEL_LEN=8192

# 是否强制使用 eager 模式（调试时使用）
ENFORCE_EAGER=False

# ==================== DeepSeek OCR 模式配置 ====================
# Tiny: base_size=512, image_size=512, crop_mode=False
# Small: base_size=640, image_size=640, crop_mode=False
# Base: base_size=1024, image_size=1024, crop_mode=False
# Large: base_size=1280, image_size=1280, crop_mode=False
# Gundam (推荐): base_size=1024, image_size=640, crop_mode=True

BASE_SIZE=1024
IMAGE_SIZE=640
CROP_MODE=True

# ==================== API 配置 ====================
API_HOST=0.0.0.0
API_PORT=8001

# 最大上传文件大小（MB）
MAX_UPLOAD_SIZE_MB=100

# ==================== Docker 配置 ====================
# 前端端口
FRONTEND_PORT=3000

# 内存限制
MEMORY_LIMIT=50g
