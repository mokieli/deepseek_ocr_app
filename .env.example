# DeepSeek-OCR vLLM Direct 环境变量示例
# 复制此文件为 .env 后根据实际情况调整取值

# ==================== 模型配置 ====================
# 模型路径（本地路径或 HuggingFace / ModelScope 模型名）
MODEL_PATH=deepseek-ai/DeepSeek-OCR

# ==================== GPU 配置 ====================
# 张量并行大小（多卡推理时设置）
TENSOR_PARALLEL_SIZE=1
# GPU 内存利用率（0.0-1.0）
GPU_MEMORY_UTILIZATION=0.9
# 最大模型长度（token 数）
MAX_MODEL_LEN=8192
# 是否强制使用 eager 模式（调试时使用）
ENFORCE_EAGER=False
# 强制启用 vLLM v1 引擎
VLLM_USE_V1=1

# ==================== DeepSeek OCR 模式 ====================
# 推荐：BASE_SIZE=1024, IMAGE_SIZE=640, CROP_MODE=True （Gundam 模式）
BASE_SIZE=1024
IMAGE_SIZE=640
CROP_MODE=True

PDF_MAX_CONCURRENCY=20
# ==================== API 配置 ====================
API_HOST=0.0.0.0
API_PORT=8001
# 最大上传文件大小（MB）
MAX_UPLOAD_SIZE_MB=100

# ==================== Docker / 前端配置 ====================
# 前端暴露端口
FRONTEND_PORT=3000
# 容器内存限制
MEMORY_LIMIT=50g

# ==================== 使用说明 ====================
# 1. 复制本文件为 .env 并按需修改
# 2. 执行 docker compose up --build 启动后端 + 前端
# 3. 后端 API: http://localhost:${API_PORT}/docs
# 4. 前端界面: http://localhost:${FRONTEND_PORT}
