# vLLM Direct å®æ–½æ€»ç»“

## å®Œæˆæ—¶é—´
2025-10-30

## å®æ–½ç›®æ ‡
å°† DeepSeek-OCR é¡¹ç›®ä» vLLM OpenAI åŒå®¹å™¨æ¶æ„è¿ç§»åˆ°åŸºäº `vllm/vllm-openai:nightly` çš„å•å®¹å™¨ vLLM Direct æ¶æ„ï¼Œè§£å†³ OpenAI API token é™åˆ¶é—®é¢˜ã€‚

## æ¶æ„å˜åŒ–

### ä¹‹å‰ï¼ˆåŒå®¹å™¨æ¶æ„ï¼‰
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      OpenAI API       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  vLLM Container â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Backend Containerâ”‚
â”‚  (æ¨ç†å¼•æ“)      â”‚      (base64 å›¾åƒ)     â”‚   (FastAPI)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†“ é—®é¢˜ï¼šå›¾åƒåºåˆ—åŒ–å¯¼è‡´ token è¿‡å¤š
```

### ç°åœ¨ï¼ˆå•å®¹å™¨æ¶æ„ï¼‰
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Single Container                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   FastAPI    â”‚â”€â”€â”€â–ºâ”‚ AsyncLLMEngine  â”‚  â”‚
â”‚  â”‚   (åç«¯)     â”‚    â”‚  (ç›´æ¥æ¨ç†)     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚          â†‘ ç›´æ¥ä¼ é€’åŸå§‹å›¾åƒç‰¹å¾             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## å·²åˆ›å»º/ä¿®æ”¹çš„æ–‡ä»¶

### æ–°å»ºæ–‡ä»¶

#### 1. æ¨¡å‹ä»£ç ï¼ˆä» third_party å¤åˆ¶ï¼‰
- âœ… `backend/app/vllm_models/__init__.py` - æ¨¡å—åˆå§‹åŒ–
- âœ… `backend/app/vllm_models/deepseek_ocr.py` - DeepSeek-OCR æ¨¡å‹å®šä¹‰
- âœ… `backend/app/vllm_models/config.py` - æ¨¡å‹é…ç½®ï¼ˆå·²é€‚é…ï¼‰
- âœ… `backend/app/vllm_models/process/` - å›¾åƒå¤„ç†æ¨¡å—
  - `__init__.py`
  - `image_process.py` - å›¾åƒé¢„å¤„ç†
  - `ngram_norepeat.py` - N-gram å»é‡
- âœ… `backend/app/vllm_models/deepencoder/` - æ·±åº¦ç¼–ç å™¨
  - `__init__.py`
  - `sam_vary_sdpa.py` - SAM ç¼–ç å™¨
  - `clip_sdpa.py` - CLIP ç¼–ç å™¨
  - `build_linear.py` - MLP æŠ•å½±å™¨

#### 2. æ ¸å¿ƒå®ç°
- âœ… `backend/app/services/vllm_direct_engine.py` - vLLM Direct å¼•æ“å®ç°

#### 3. éƒ¨ç½²é…ç½®
- âœ… `backend/Dockerfile.vllm-direct` - å•å®¹å™¨ Dockerfile
- âœ… `backend/requirements-vllm-direct.txt` - Python ä¾èµ–
- âœ… `docker-compose.vllm-direct.yml` - Docker Compose é…ç½®

#### 4. æ–‡æ¡£å’Œé…ç½®
- âœ… `.env.vllm-direct` - é…ç½®æ–‡ä»¶æ¨¡æ¿
- âœ… `docs/vllm-direct/README.md` - è¯¦ç»†ä½¿ç”¨æ–‡æ¡£
- âœ… `start-vllm-direct.sh` - å¿«é€Ÿå¯åŠ¨è„šæœ¬
- âœ… `docs/vllm-direct/implementation-summary.md` - æœ¬æ–‡æ¡£

### ä¿®æ”¹çš„æ–‡ä»¶

#### 1. åç«¯ä»£ç 
- âœ… `backend/app/config.py` - æ·»åŠ  vLLM Direct é…ç½®é¡¹
- âœ… `backend/app/api/routes.py` - æ”¯æŒå¤šç§æ¨ç†å¼•æ“
- âœ… `backend/app/main.py` - æ›´æ–°å¯åŠ¨ä¿¡æ¯ï¼ˆv4.0.0ï¼‰

#### 2. æ¨¡å‹ä»£ç è°ƒæ•´
- âœ… `backend/app/vllm_models/config.py` - å»¶è¿Ÿåˆå§‹åŒ– tokenizer
- âœ… `backend/app/vllm_models/process/image_process.py` - ä¿®å¤å¯¼å…¥è·¯å¾„
- âœ… `backend/app/vllm_models/deepseek_ocr.py` - ä¿®å¤å¯¼å…¥è·¯å¾„

## å…³é”®ç‰¹æ€§

### 1. ç›´æ¥æ¨ç†
- ä½¿ç”¨ `AsyncLLMEngine.generate()` ç›´æ¥ä¼ é€’å›¾åƒç‰¹å¾
- é¿å… OpenAI API çš„åºåˆ—åŒ–å¼€é”€
- æ”¯æŒè¶…é•¿ token åºåˆ—

### 2. çµæ´»é…ç½®
- æ”¯æŒå¤šç§ OCR æ¨¡å¼ï¼ˆTiny/Small/Base/Large/Gundamï¼‰
- å¯è°ƒæ•´ GPU å†…å­˜åˆ©ç”¨ç‡
- æ”¯æŒå¼ é‡å¹¶è¡Œï¼ˆå¤šå¡æ¨ç†ï¼‰

### 3. å…¼å®¹æ€§
- ä¿æŒåŸæœ‰ API ç«¯ç‚¹ä¸å˜
- æ”¯æŒåŠ¨æ€åˆ‡æ¢æ¨ç†å¼•æ“ï¼ˆé€šè¿‡ `INFERENCE_ENGINE` ç¯å¢ƒå˜é‡ï¼‰
- å‰ç«¯æ— éœ€ä¿®æ”¹

### 4. å®˜æ–¹é•œåƒ
- åŸºäº `vllm/vllm-openai:nightly`
- è‡ªåŠ¨è·å–æœ€æ–°ä¼˜åŒ–
- ç¨³å®šå¯é 

## ä½¿ç”¨æ–¹å¼

### å¿«é€Ÿå¯åŠ¨
```bash
# 1. å¤åˆ¶é…ç½®
cp .env.vllm-direct .env

# 2. ä½¿ç”¨å¯åŠ¨è„šæœ¬ï¼ˆæ¨èï¼‰
./start-vllm-direct.sh

# æˆ–è€…æ‰‹åŠ¨å¯åŠ¨
docker-compose -f docker-compose.vllm-direct.yml up -d
```

### é…ç½®æ¨¡å‹è·¯å¾„
```bash
# åœ¨ .env ä¸­è®¾ç½®
MODEL_PATH=deepseek-ai/DeepSeek-OCR  # ä» HuggingFace/ModelScope è‡ªåŠ¨ä¸‹è½½
# æˆ–
MODEL_PATH=/root/.cache/modelscope/deepseek-ai/DeepSeek-OCR  # ä½¿ç”¨æœ¬åœ°æ¨¡å‹
```

### å¤šå¡æ¨ç†
```bash
# åœ¨ .env ä¸­è®¾ç½®
TENSOR_PARALLEL_SIZE=2

# åœ¨ docker-compose.vllm-direct.yml ä¸­æŒ‡å®š GPU
device_ids: ["0", "1"]
```

## æµ‹è¯•éªŒè¯

### 1. å¥åº·æ£€æŸ¥
```bash
curl http://localhost:8001/health
```

é¢„æœŸå“åº”ï¼š
```json
{
  "status": "healthy",
  "model_loaded": true,
  "inference_engine": "vllm_direct"
}
```

### 2. OCR æµ‹è¯•
```bash
curl -X POST "http://localhost:8001/api/ocr" \
  -F "image=@test.jpg" \
  -F "mode=markdown" \
  -F "grounding=true"
```

### 3. æ€§èƒ½æµ‹è¯•
- é¦–æ¬¡æ¨ç†ä¼šç¨æ…¢ï¼ˆæ¨¡å‹åˆå§‹åŒ–ï¼‰
- åç»­æ¨ç†åº”è¯¥éå¸¸å¿«
- å¯ä»¥å¤„ç†å¤§å°ºå¯¸å›¾åƒè€Œä¸ä¼šå›  token é™åˆ¶å¤±è´¥

## ä¼˜åŠ¿æ€»ç»“

### âœ… è§£å†³çš„é—®é¢˜
1. **Token é™åˆ¶** - ä¸å†å— OpenAI API token æ•°é™åˆ¶
2. **éƒ¨ç½²å¤æ‚åº¦** - ä»åŒå®¹å™¨ç®€åŒ–ä¸ºå•å®¹å™¨
3. **é€šä¿¡å¼€é”€** - æ¶ˆé™¤å®¹å™¨é—´ç½‘ç»œå»¶è¿Ÿ
4. **çµæ´»æ€§** - å®Œå…¨æ§åˆ¶æ¨ç†æµç¨‹

### âœ… ä¿æŒçš„ä¼˜åŠ¿
1. **é«˜æ€§èƒ½** - vLLM å¼•æ“çš„æ‰€æœ‰ä¼˜åŒ–
2. **æ˜“ç”¨æ€§** - API ç«¯ç‚¹ä¿æŒä¸å˜
3. **å®˜æ–¹æ”¯æŒ** - ä½¿ç”¨å®˜æ–¹ vLLM é•œåƒ
4. **å¯æ‰©å±•æ€§** - æ”¯æŒå¤šå¡ã€å¤šèŠ‚ç‚¹

## åç»­å»ºè®®

### 1. æ€§èƒ½ä¼˜åŒ–
- [ ] æ ¹æ®å®é™…ä½¿ç”¨è°ƒæ•´ `GPU_MEMORY_UTILIZATION`
- [ ] æµ‹è¯•ä¸åŒ `MAX_MODEL_LEN` å¯¹æ€§èƒ½çš„å½±å“
- [ ] è€ƒè™‘å¯ç”¨ FlashAttention-2

### 2. ç›‘æ§
- [ ] æ·»åŠ  Prometheus metrics
- [ ] é›†æˆæ—¥å¿—èšåˆç³»ç»Ÿ
- [ ] ç›‘æ§ GPU åˆ©ç”¨ç‡

### 3. æ‰©å±•
- [ ] æ”¯æŒæ‰¹é‡æ¨ç†
- [ ] æ·»åŠ æ¨ç†ç¼“å­˜
- [ ] å®ç°è¯·æ±‚é˜Ÿåˆ—ç®¡ç†

## å…¼å®¹æ€§è¯´æ˜

### å‘åå…¼å®¹
- ä¿ç•™äº† vLLM OpenAI æ¨¡å¼çš„æ”¯æŒ
- å¯ä»¥é€šè¿‡ `INFERENCE_ENGINE=vllm_openai` åˆ‡æ¢å›æ—§æ¨¡å¼
- API ç«¯ç‚¹å®Œå…¨å…¼å®¹

### è¿ç§»è·¯å¾„
```bash
# ä»æ—§æ¶æ„è¿ç§»
1. åœæ­¢æ—§æœåŠ¡: docker-compose -f docker-compose.vllm.yml down
2. å¤åˆ¶é…ç½®: cp .env.vllm-direct .env
3. å¯åŠ¨æ–°æœåŠ¡: ./start-vllm-direct.sh
4. éªŒè¯åŠŸèƒ½: curl http://localhost:8001/health
```

## æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜
1. **OOM é”™è¯¯** â†’ å‡å°‘ `GPU_MEMORY_UTILIZATION` æˆ– `MAX_MODEL_LEN`
2. **æ¨ç†æ…¢** â†’ å¢åŠ  `GPU_MEMORY_UTILIZATION`ï¼Œæ£€æŸ¥ GPU åˆ©ç”¨ç‡
3. **æ¨¡å‹åŠ è½½å¤±è´¥** â†’ æ£€æŸ¥ `MODEL_PATH` å’Œç½‘ç»œè¿æ¥
4. **CUDA é”™è¯¯** â†’ æ£€æŸ¥ NVIDIA é©±åŠ¨ç‰ˆæœ¬

è¯¦ç»†æ•…éšœæ’æŸ¥è§ [vLLM Direct æŒ‡å—](./README.md)

## æŠ€æœ¯ç»†èŠ‚

### æ ¸å¿ƒå®ç°
- **å¼•æ“**: `vllm.AsyncLLMEngine`
- **æ¨¡å‹æ³¨å†Œ**: `vllm.model_executor.models.registry.ModelRegistry`
- **å›¾åƒå¤„ç†**: `DeepseekOCRProcessor.tokenize_with_images()`
- **é‡‡æ ·æ§åˆ¶**: `NoRepeatNGramLogitsProcessor`

### ä¾èµ–ç‰ˆæœ¬
- vLLM: latest (from nightly image)
- PyTorch: 2.6.0
- Transformers: 4.48.2
- FastAPI: 0.115.12

## æ€»ç»“

æˆåŠŸå®ç°äº†ä» vLLM OpenAI åŒå®¹å™¨æ¶æ„åˆ° vLLM Direct å•å®¹å™¨æ¶æ„çš„è¿ç§»ï¼š

- âœ… æ‰€æœ‰ 8 ä¸ª TODO ä»»åŠ¡å·²å®Œæˆ
- âœ… å®Œæ•´çš„ä»£ç å®ç°å’Œé…ç½®æ–‡ä»¶
- âœ… è¯¦ç»†çš„æ–‡æ¡£å’Œä½¿ç”¨æŒ‡å—
- âœ… å¿«é€Ÿå¯åŠ¨è„šæœ¬
- âœ… ä¿æŒå‘åå…¼å®¹

ç”¨æˆ·ç°åœ¨å¯ä»¥ç›´æ¥ä½¿ç”¨ `./start-vllm-direct.sh` å¿«é€Ÿå¯åŠ¨æœåŠ¡ï¼Œäº«å—æ—  token é™åˆ¶ã€é«˜æ€§èƒ½çš„ OCR æ¨ç†ä½“éªŒï¼ğŸš€
